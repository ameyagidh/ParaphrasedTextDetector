{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:44:56.751932Z",
     "iopub.status.busy": "2023-03-22T15:44:56.751643Z",
     "iopub.status.idle": "2023-03-22T15:45:24.159362Z",
     "shell.execute_reply": "2023-03-22T15:45:24.158316Z",
     "shell.execute_reply.started": "2023-03-22T15:44:56.751872Z"
    },
    "id": "oOXsh96-ZD42"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-22T15:45:58.137329Z",
     "iopub.status.busy": "2023-03-22T15:45:58.136969Z",
     "iopub.status.idle": "2023-03-22T15:46:03.039128Z",
     "shell.execute_reply": "2023-03-22T15:46:03.038048Z",
     "shell.execute_reply.started": "2023-03-22T15:45:58.137277Z"
    },
    "id": "zJWQxcr-ZD43",
    "outputId": "032695c3-832c-435b-b486-4c51f65a9223"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ameyagidh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ameyagidh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe and computation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#NLTK and regex libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "\n",
    "#Sklearn libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Downloads for string cleaning\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfU1jtemi8mQ"
   },
   "source": [
    "Import and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2023-03-22T15:48:08.129279Z",
     "iopub.status.busy": "2023-03-22T15:48:08.128938Z",
     "iopub.status.idle": "2023-03-22T15:48:09.662639Z",
     "shell.execute_reply": "2023-03-22T15:48:09.661559Z",
     "shell.execute_reply.started": "2023-03-22T15:48:08.129222Z"
    },
    "id": "gPnVYDm7ZD45"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/paws/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "execution": {
     "iopub.execute_input": "2023-03-22T15:48:10.806518Z",
     "iopub.status.busy": "2023-03-22T15:48:10.806176Z",
     "iopub.status.idle": "2023-03-22T15:48:10.826183Z",
     "shell.execute_reply": "2023-03-22T15:48:10.825395Z",
     "shell.execute_reply.started": "2023-03-22T15:48:10.806468Z"
    },
    "id": "HWChYaa6ZD45",
    "outputId": "af065a4e-abfc-427a-d72a-d380ab17eb2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In Paris , in October 1560 , he secretly met t...</td>\n",
       "      <td>In October 1560 , he secretly met with the Eng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>There are also specific discussions , public p...</td>\n",
       "      <td>There are also public discussions , profile sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          sentence1  \\\n",
       "0           0  In Paris , in October 1560 , he secretly met t...   \n",
       "1           1  The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "2           2  There are also specific discussions , public p...   \n",
       "3           3  When comparable rates of flow can be maintaine...   \n",
       "4           4  It is the seat of Zerendi District in Akmola R...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  In October 1560 , he secretly met with the Eng...      0  \n",
       "1  The 1975 -- 76 season of the National Basketba...      1  \n",
       "2  There are also public discussions , profile sp...      0  \n",
       "3  The results are high when comparable flow rate...      1  \n",
       "4  It is the seat of the district of Zerendi in A...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN73N3Yxi_VZ"
   },
   "source": [
    "## Function to clean strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UmNnQmoLaeUA"
   },
   "outputs": [],
   "source": [
    "# Cleaning function for the strings\n",
    "def clean_string(input_str):\n",
    "    \n",
    "    # Lowercase the input_string\n",
    "    input_str = input_str.lower()\n",
    "    \n",
    "    # Remove URLs, links\n",
    "    input_str = re.sub(r\"http\\S+\", \"\", input_str)\n",
    "    input_str = re.sub(r\"www.\\S+\", \"\", input_str)\n",
    "    input_str = re.sub(r\"\\S+@\\S+\", \"\", input_str)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    input_str_punc = \"\".join(char for char in input_str if char not in string.punctuation)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    input_str_stopwords = \" \".join([word for word in re.split('\\W+', input_str_punc) if word not in stopword])\n",
    "    \n",
    "    # Lemmatization\n",
    "    input_str_cleaned = \" \".join([wn.lemmatize(word,'n') for word in re.split('\\W+', input_str_stopwords)])\n",
    "\n",
    "    return input_str_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BCHPTZdjBfz"
   },
   "source": [
    "### Apply cleaning function to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In Paris , in October 1560 , he secretly met t...</td>\n",
       "      <td>In October 1560 , he secretly met with the Eng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>There are also specific discussions , public p...</td>\n",
       "      <td>There are also public discussions , profile sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49396</th>\n",
       "      <td>49396</td>\n",
       "      <td>`` Our school is of spiritual and spiritual , ...</td>\n",
       "      <td>`` Our School is of the Temporal and the Spiri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49397</th>\n",
       "      <td>49397</td>\n",
       "      <td>She was in Cork on June 24 and arrived on 8 Ju...</td>\n",
       "      <td>She was at Cork on 24 June , and arrived in th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49398</th>\n",
       "      <td>49398</td>\n",
       "      <td>Cornelia Stuyvesant Vanderbilt ( George and Ed...</td>\n",
       "      <td>John John F. A. Cecil ( the only child of Geor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49399</th>\n",
       "      <td>49399</td>\n",
       "      <td>The third season was premiered on 7 June 2010 ...</td>\n",
       "      <td>The fourth season was premiered on June 7 , 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49400</th>\n",
       "      <td>49400</td>\n",
       "      <td>It is also from a location on the mainland Los...</td>\n",
       "      <td>It is also known from one location on the main...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49401 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          sentence1  \\\n",
       "0               0  In Paris , in October 1560 , he secretly met t...   \n",
       "1               1  The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "2               2  There are also specific discussions , public p...   \n",
       "3               3  When comparable rates of flow can be maintaine...   \n",
       "4               4  It is the seat of Zerendi District in Akmola R...   \n",
       "...           ...                                                ...   \n",
       "49396       49396  `` Our school is of spiritual and spiritual , ...   \n",
       "49397       49397  She was in Cork on June 24 and arrived on 8 Ju...   \n",
       "49398       49398  Cornelia Stuyvesant Vanderbilt ( George and Ed...   \n",
       "49399       49399  The third season was premiered on 7 June 2010 ...   \n",
       "49400       49400  It is also from a location on the mainland Los...   \n",
       "\n",
       "                                               sentence2  label  \n",
       "0      In October 1560 , he secretly met with the Eng...      0  \n",
       "1      The 1975 -- 76 season of the National Basketba...      1  \n",
       "2      There are also public discussions , profile sp...      0  \n",
       "3      The results are high when comparable flow rate...      1  \n",
       "4      It is the seat of the district of Zerendi in A...      1  \n",
       "...                                                  ...    ...  \n",
       "49396  `` Our School is of the Temporal and the Spiri...      0  \n",
       "49397  She was at Cork on 24 June , and arrived in th...      1  \n",
       "49398  John John F. A. Cecil ( the only child of Geor...      0  \n",
       "49399  The fourth season was premiered on June 7 , 20...      0  \n",
       "49400  It is also known from one location on the main...      0  \n",
       "\n",
       "[49401 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rly9En0UamuA"
   },
   "outputs": [],
   "source": [
    "df[\"question1\"] = df[\"sentence1\"].apply(lambda x: clean_string(str(x)))\n",
    "df[\"question2\"] = df[\"sentence2\"].apply(lambda x: clean_string(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9jW62KvjEwE"
   },
   "source": [
    "### Split the testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Dl0B_c5Ia1tm"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:48:32.896526Z",
     "iopub.status.busy": "2023-03-22T15:48:32.896178Z",
     "iopub.status.idle": "2023-03-22T15:48:33.020786Z",
     "shell.execute_reply": "2023-03-22T15:48:33.019985Z",
     "shell.execute_reply.started": "2023-03-22T15:48:32.896475Z"
    },
    "id": "jfYv1Rc0ZD46"
   },
   "outputs": [],
   "source": [
    "sent_1_train = train[\"question1\"].values\n",
    "sent_2_train = train[\"question2\"].values\n",
    "Y_train = train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "h_kbHGPzedPG"
   },
   "outputs": [],
   "source": [
    "sent_1_test = test[\"question1\"].values\n",
    "sent_2_test = test[\"question2\"].values\n",
    "Y_test = test[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rljIskL3j1Pn"
   },
   "source": [
    "### tokenizing and padding training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:49:10.326757Z",
     "iopub.status.busy": "2023-03-22T15:49:10.326413Z",
     "iopub.status.idle": "2023-03-22T15:49:30.243309Z",
     "shell.execute_reply": "2023-03-22T15:49:30.242175Z",
     "shell.execute_reply.started": "2023-03-22T15:49:10.326705Z"
    },
    "id": "8eCf5bRkZD49"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 200000)\n",
    "tokenizer.fit_on_texts(list(sent_1_train)+list(sent_2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:49:48.096666Z",
     "iopub.status.busy": "2023-03-22T15:49:48.096325Z",
     "iopub.status.idle": "2023-03-22T15:50:10.404545Z",
     "shell.execute_reply": "2023-03-22T15:50:10.403698Z",
     "shell.execute_reply.started": "2023-03-22T15:49:48.096611Z"
    },
    "id": "O5wvNbD1ZD4-"
   },
   "outputs": [],
   "source": [
    "\n",
    "sent_1_train = tokenizer.texts_to_sequences(sent_1_train)\n",
    "sent_1_train_pad = pad_sequences(sent_1_train, maxlen = 30, padding='post')\n",
    "\n",
    "\n",
    "sent_2_train = tokenizer.texts_to_sequences(sent_2_train)\n",
    "sent_2_train_pad = pad_sequences(sent_2_train, maxlen = 30, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:50:16.489023Z",
     "iopub.status.busy": "2023-03-22T15:50:16.488618Z",
     "iopub.status.idle": "2023-03-22T15:50:35.531930Z",
     "shell.execute_reply": "2023-03-22T15:50:35.531035Z",
     "shell.execute_reply.started": "2023-03-22T15:50:16.488967Z"
    },
    "id": "EnVn4RtpZD4-"
   },
   "outputs": [],
   "source": [
    "sent_1_test = tokenizer.texts_to_sequences(sent_1_test)\n",
    "sent_1_test_pad = pad_sequences(sent_1_test,maxlen = 30, padding='post')\n",
    "\n",
    "sent_2_test = tokenizer.texts_to_sequences(sent_2_test)\n",
    "sent_2_test_pad = pad_sequences(sent_2_test, maxlen = 30, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__RUcJj_j4Qu"
   },
   "source": [
    "### Create glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:50:39.154190Z",
     "iopub.status.busy": "2023-03-22T15:50:39.153804Z",
     "iopub.status.idle": "2023-03-22T15:51:01.466886Z",
     "shell.execute_reply": "2023-03-22T15:51:01.465854Z",
     "shell.execute_reply.started": "2023-03-22T15:50:39.154137Z"
    },
    "id": "8YSsky7GZD4-"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_index = {}\n",
    "with open('../data/glove.6B.200d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:], 'float32')\n",
    "        embedding_index[word] = vectors\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:51:17.914007Z",
     "iopub.status.busy": "2023-03-22T15:51:17.913637Z",
     "iopub.status.idle": "2023-03-22T15:51:18.195777Z",
     "shell.execute_reply": "2023-03-22T15:51:18.194861Z",
     "shell.execute_reply.started": "2023-03-22T15:51:17.913950Z"
    },
    "id": "-O2SZhzHZD4-"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index)+1, 200))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCDLZ-Ucj6GQ"
   },
   "source": [
    "### Tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-22T15:51:19.880146Z",
     "iopub.status.busy": "2023-03-22T15:51:19.879775Z",
     "iopub.status.idle": "2023-03-22T15:51:23.155018Z",
     "shell.execute_reply": "2023-03-22T15:51:23.154138Z",
     "shell.execute_reply.started": "2023-03-22T15:51:19.880095Z"
    },
    "id": "EGphZvHlZD4-",
    "outputId": "f5a23d69-f45a-447c-b6fc-258fff8cca6b"
   },
   "outputs": [],
   "source": [
    "# Question 1 model\n",
    "model_q1 = tf.keras.Sequential()\n",
    "model_q1.add(Embedding(input_dim = len(word_index)+1,\n",
    "                       output_dim = 200,\n",
    "                      weights = [embedding_matrix],\n",
    "                      input_length = 30))\n",
    "model_q1.add(LSTM(128, activation = 'relu', return_sequences = True))\n",
    "model_q1.add(Dropout(0.25))\n",
    "model_q1.add(LSTM(128, return_sequences = True))\n",
    "model_q1.add(Dropout(0.25))\n",
    "model_q1.add(Dense(64, activation = 'relu'))\n",
    "model_q1.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-22T15:51:27.609048Z",
     "iopub.status.busy": "2023-03-22T15:51:27.608666Z",
     "iopub.status.idle": "2023-03-22T15:51:28.458797Z",
     "shell.execute_reply": "2023-03-22T15:51:28.458022Z",
     "shell.execute_reply.started": "2023-03-22T15:51:27.608994Z"
    },
    "id": "ljlaOiIEZD4_",
    "outputId": "e1e49134-843b-4d03-8c52-5464bc47dba9"
   },
   "outputs": [],
   "source": [
    "# Quesiton 2 model\n",
    "model_q2 = tf.keras.Sequential()\n",
    "model_q2.add(Embedding(input_dim = len(word_index)+1,\n",
    "                       output_dim = 200,\n",
    "                      weights = [embedding_matrix],\n",
    "                      input_length = 30))\n",
    "model_q2.add(LSTM(128, activation = 'relu', return_sequences = True))\n",
    "model_q2.add(Dropout(0.25))\n",
    "model_q2.add(LSTM(128, return_sequences = True))\n",
    "model_q1.add(Dropout(0.25))\n",
    "model_q2.add(Dense(64, activation = 'relu'))\n",
    "model_q2.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T15:51:31.190726Z",
     "iopub.status.busy": "2023-03-22T15:51:31.190391Z",
     "iopub.status.idle": "2023-03-22T15:51:31.249163Z",
     "shell.execute_reply": "2023-03-22T15:51:31.248346Z",
     "shell.execute_reply.started": "2023-03-22T15:51:31.190676Z"
    },
    "id": "vc5jMVQfZD4_"
   },
   "outputs": [],
   "source": [
    "# Merging model output\n",
    "mergedOut = Multiply()([model_q1.output, model_q2.output])\n",
    "\n",
    "mergedOut = Flatten()(mergedOut)\n",
    "mergedOut = Dense(128, activation = 'relu')(mergedOut)\n",
    "mergedOut = Dropout(0.25)(mergedOut)\n",
    "mergedOut = Dense(64, activation = 'relu')(mergedOut)\n",
    "mergedOut = Dropout(0.25)(mergedOut)\n",
    "mergedOut = Dense(2, activation = 'sigmoid')(mergedOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4xOonJ4j73z"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-03-22T15:51:32.646204Z",
     "iopub.status.busy": "2023-03-22T15:51:32.645826Z",
     "iopub.status.idle": "2023-03-22T16:14:34.564875Z",
     "shell.execute_reply": "2023-03-22T16:14:34.564011Z",
     "shell.execute_reply.started": "2023-03-22T15:51:32.646154Z"
    },
    "id": "c5-ugOt_ZD4_",
    "outputId": "e79be70d-0aba-43ed-b6a8-2c39941aadb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 06:38:28.319974: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 60s 3s/step - loss: 0.6920 - accuracy: 0.5417 - val_loss: 0.6871 - val_accuracy: 0.5573\n",
      "Epoch 2/6\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.6869 - accuracy: 0.5585 - val_loss: 0.6865 - val_accuracy: 0.5573\n",
      "Epoch 3/6\n",
      "18/18 [==============================] - 37s 2s/step - loss: 0.6863 - accuracy: 0.5585 - val_loss: 0.6863 - val_accuracy: 0.5573\n",
      "Epoch 4/6\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.6862 - accuracy: 0.5585 - val_loss: 0.6864 - val_accuracy: 0.5573\n",
      "Epoch 5/6\n",
      "18/18 [==============================] - 52s 3s/step - loss: 0.6857 - accuracy: 0.5585 - val_loss: 0.6863 - val_accuracy: 0.5573\n",
      "Epoch 6/6\n",
      "18/18 [==============================] - 45s 3s/step - loss: 0.6852 - accuracy: 0.5585 - val_loss: 0.6861 - val_accuracy: 0.5573\n"
     ]
    }
   ],
   "source": [
    "new_model = Model([model_q1.input, model_q2.input], mergedOut)\n",
    "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = new_model.fit([sent_1_train_pad,sent_2_train_pad],Y_train, batch_size = 2000, epochs = 6,validation_data=([sent_1_test_pad,sent_2_test_pad],Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
